---
layout: home
title: "Home"
---

<div style="text-align: center; margin-top: 50px;">
  <h1 style="font-size: 2.5em; font-weight: bold; color: #2c3e50; text-shadow: 2px 2px #ecf0f1;">
    Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text
  </h1>
</div>

<div style="text-align: center; margin-top: 30px;">
  <p style="font-size: 1.2em; color: #34495e;">
    This comprehensive tutorial is designed to educate participants on distinguishing AI-generated text from human-written content. It delves into the transformative impact of large language models on natural language processing and explores the challenges and techniques involved in detecting AI-generated text.
  </p>
</div>

{:.no_toc}

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Abstract
Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP), enabling applications from question answering to text generation. However, distinguishing between human and AI-generated text is increasingly critical due to the sophistication of modern models. This tutorial addresses the need for robust detection techniques, exploring existing strategies, their vulnerabilities, and broader implications. Our goals are to:
1. Investigate the risks and ethical challenges related to AI-generated text.
2. Provide an overview of AI-generated text detection methods, highlighting both traditional and cutting-edge techniques.
3. Discuss the vulnerabilities of current detection methods and the feasibility of detection from a theoretical perspective.

This tutorial offers valuable insights for researchers, practitioners, and policymakers in AI, cybersecurity, ethics, and beyond.

## What To Expect
This tutorial aims to cater to a diverse audience, including data scientists, AI researchers, cybersecurity professionals, digital content creators, legal experts, and policymakers. Our ideal participants are individuals engaged in fields where AI-generated text plays a pivotal role, such as natural language generation (NLG), information security, misinformation detection, digital media, and legal and ethical studies of AI technologies. While a foundational understanding of AI principles and NLP is advantageous, it is not a strict requirement. We enthusiastically welcome participants with a keen interest in exploring the ethical, technical, and societal dimensions of AI-generated text, regardless of their technical background. The tutorial is thoughtfully structured to provide valuable insights across various levels of expertise, ensuring that all attendees, even those with minimal exposure to AI principles, gain clarity and find value in our discussions.

Participants can expect to:
- Understand the risks and misuse of AI-generated text.
- Learn about various detection techniques and their applications.
- Explore the vulnerabilities of current detection methods.
- Gain insights into the theoretical perspectives on detection feasibility.

## Explore the Tutorial
For detailed information on the topics covered in this tutorial, visit the [Tutorial Outline](./tutorial-outline).

## Meet the Tutors
Learn more about our expert tutors on the [Tutors and Contributors](./authors) page.

Explore the sections to learn more about the transformative impact of LLMs on NLP, the risks associated with AI-generated text, the detection techniques used, and the future of this exciting field.

{% include site.aux_links %}
